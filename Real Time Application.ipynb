{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "mixer.music.load(\"kikeriki.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = \"haarcascade_xml/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(xml_path + \"haarcascade_frontalface_default.xml\")\n",
    "right_eye_cascade = cv2.CascadeClassifier(xml_path + \"haarcascade_righteye_2splits.xml\")\n",
    "left_eye_cascade = cv2.CascadeClassifier(xml_path + \"haarcascade_lefteye_2splits.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(xml_path + \"haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (80,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right: [[0.998608]]  Left: [[0.99999475]]\n",
      "Right: [[0.96075106]]  Left: [[0.99794686]]\n",
      "Right: [[0.9999719]]  Left: [[0.99999154]]\n",
      "Right: [[0.99912405]]  Left: [[0.9267465]]\n",
      "Right: [[0.9999684]]  Left: [[0.99983835]]\n",
      "Right: [[0.9999393]]  Left: [[0.9998898]]\n",
      "Right: [[0.99948263]]  Left: [[0.9994789]]\n",
      "Right: [[0.99981827]]  Left: [[0.99305487]]\n",
      "Right: [[0.9993479]]  Left: [[0.9989004]]\n",
      "Right: [[0.9999073]]  Left: [[0.9866234]]\n",
      "Right: [[0.99923635]]  Left: [[0.999995]]\n",
      "Right: [[0.99993646]]  Left: [[0.9998509]]\n",
      "Right: [[0.9985889]]  Left: [[0.99999976]]\n",
      "Right: [[0.8261149]]  Left: [[0.06758052]]\n",
      "Right: [[0.00098562]]  Left: [[0.06590068]]\n",
      "Right: [[0.04207584]]  Left: [[0.10826752]]\n",
      "Right: [[0.03736061]]  Left: [[0.00088915]]\n",
      "Right: [[0.00292182]]  Left: [[0.00052622]]\n",
      "Pay attention!\n",
      "Right: [[0.00116077]]  Left: [[0.00040519]]\n",
      "Right: [[0.00023481]]  Left: [[8.7361725e-05]]\n",
      "Right: [[1.6815382e-05]]  Left: [[0.00215316]]\n",
      "Right: [[9.39891e-06]]  Left: [[0.00144917]]\n",
      "Right: [[0.9977429]]  Left: [[0.9995706]]\n",
      "Right: [[0.9998164]]  Left: [[0.9932805]]\n",
      "Right: [[0.99973696]]  Left: [[0.9955051]]\n",
      "Right: [[0.9987963]]  Left: [[0.94454575]]\n",
      "Right: [[0.99979115]]  Left: [[0.9969504]]\n",
      "Right: [[0.9998138]]  Left: [[0.99678254]]\n",
      "Right: [[0.9998695]]  Left: [[0.99891204]]\n",
      "Right: [[0.998804]]  Left: [[0.99947655]]\n",
      "Right: [[0.95985055]]  Left: [[0.00445524]]\n",
      "Right: [[0.00319284]]  Left: [[9.595825e-05]]\n",
      "Right: [[0.01943734]]  Left: [[0.00013795]]\n",
      "Right: [[0.00357196]]  Left: [[0.00064147]]\n",
      "Right: [[0.66112185]]  Left: [[0.00047141]]\n",
      "Right: [[0.00248194]]  Left: [[0.00015885]]\n",
      "Right: [[0.00093293]]  Left: [[0.00011136]]\n",
      "Right: [[4.1729254e-06]]  Left: [[0.00024322]]\n",
      "Right: [[0.01034573]]  Left: [[7.9821584e-05]]\n",
      "Pay attention!\n",
      "Right: [[0.0007613]]  Left: [[0.00011328]]\n",
      "Right: [[7.1240574e-05]]  Left: [[3.286479e-05]]\n",
      "Right: [[0.00042206]]  Left: [[0.00022429]]\n",
      "Right: [[0.00264463]]  Left: [[9.839618e-06]]\n",
      "Right: [[6.55312e-05]]  Left: [[5.2622418e-05]]\n",
      "Right: [[0.00128108]]  Left: [[0.00011543]]\n",
      "Right: [[5.587427e-06]]  Left: [[0.00091007]]\n",
      "Right: [[4.1586412e-05]]  Left: [[0.00049931]]\n",
      "Right: [[8.849788e-05]]  Left: [[0.00011314]]\n",
      "Pay attention!\n",
      "Right: [[0.00096601]]  Left: [[7.0978334e-05]]\n",
      "Right: [[0.00022677]]  Left: [[3.85327e-05]]\n",
      "Right: [[0.00093684]]  Left: [[0.00057936]]\n",
      "Right: [[0.00025982]]  Left: [[0.00141403]]\n",
      "Right: [[0.00338477]]  Left: [[7.108665e-05]]\n",
      "Right: [[0.00019053]]  Left: [[0.00106248]]\n",
      "Right: [[0.3539107]]  Left: [[1.9477167e-05]]\n",
      "Right: [[0.99742734]]  Left: [[0.97372055]]\n",
      "Right: [[0.9986406]]  Left: [[0.99974877]]\n",
      "Right: [[0.99991435]]  Left: [[0.99996436]]\n",
      "Right: [[0.9980788]]  Left: [[0.99500084]]\n",
      "Right: [[0.997555]]  Left: [[0.9982053]]\n",
      "Right: [[0.9903281]]  Left: [[0.9926971]]\n",
      "Right: [[0.99355483]]  Left: [[0.96354735]]\n",
      "Right: [[0.99670076]]  Left: [[0.62973064]]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "closed_count = 0\n",
    "frame_count = 0\n",
    "closed_tol_count = 0\n",
    "\n",
    "start = time.time()\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    gray_single = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gray = np.zeros_like(frame)\n",
    "    gray[:,:,0] = gray_single\n",
    "    gray[:,:,1] = gray_single\n",
    "    gray[:,:,2] = gray_single\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        (x,y,w,h) = faces[0]\n",
    "\n",
    "        #img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        half_int = int(np.ceil(w/2))\n",
    "\n",
    "        roi_gray_left = gray[y:y+h, x:x+half_int]\n",
    "        roi_gray_right = gray[y:y+h, x+half_int:x+w]\n",
    "\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+half_int,y+h),(255,0,0),2) # left part\n",
    "        frame = cv2.rectangle(frame,(x+half_int,y),(x+w,y+h),(0,255,0),2) # right part\n",
    "\n",
    "        roi_color_left = frame[y:y+h, x:x+half_int]\n",
    "        roi_color_right = frame[y:y+h, x+half_int:x+w]\n",
    "\n",
    "        right_eyes = right_eye_cascade.detectMultiScale(roi_gray_left)\n",
    "        left_eyes = left_eye_cascade.detectMultiScale(roi_gray_right)\n",
    "\n",
    "        # check we have detected something on both sides\n",
    "        if len(right_eyes) > 0 and len(left_eyes) > 0:\n",
    "            (rx,ry,rw,rh) = right_eyes[0]\n",
    "            (lx,ly,lw,lh) = left_eyes[0]\n",
    "\n",
    "\n",
    "            cv2.rectangle(roi_color_left,(rx,ry),(rx+rw,ry+rh),(0,255,0),2)\n",
    "            cv2.rectangle(roi_color_right,(lx,ly),(lx+lw,ly+lh),(0,255,0),2)\n",
    "\n",
    "            #take right eye image\n",
    "            right_eye = roi_gray_left[ry:ry+rh, rx:rx+rw]\n",
    "            left_eye = roi_gray_right[ly:ly+lh, lx:lx+lw]\n",
    "            \n",
    "            #cv2.imshow('frame',left_eye)\n",
    "            \n",
    "            right_eye_resized = cv2.resize(right_eye, dim, interpolation = cv2.INTER_AREA)\n",
    "            left_eye_resized = cv2.resize(left_eye, dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            right_eye_resized = right_eye_resized/255.0\n",
    "            left_eye_resized = left_eye_resized/255.0\n",
    "            \n",
    "            left_mirror = cv2.flip(left_eye_resized, 1)\n",
    "            #cv2.imshow('frame',left_mirror)\n",
    "            \n",
    "            right_final = tf.data.Dataset.from_tensor_slices([right_eye_resized])\n",
    "            left_final = tf.data.Dataset.from_tensor_slices([left_mirror])\n",
    "            \n",
    "            \n",
    "            right_open = model.predict(right_final.batch(32))\n",
    "            left_open = model.predict(left_final.batch(32))\n",
    "            \n",
    "            print(\"Right:\", right_open, \" Left:\", left_open)\n",
    "            \n",
    "            if right_open[0][0] < 0.5 and left_open[0][0] < 0.5:\n",
    "                closed_count += 1\n",
    "                cv2.putText(frame,'CLOSED', \n",
    "                    (500,460), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1,\n",
    "                    (0,0,255),\n",
    "                    2)\n",
    "                close_tol_count = 0\n",
    "                #print(\"Closed eyes found\")\n",
    "            else:\n",
    "                closed_tol_count += 1\n",
    "                if closed_tol_count > 4:\n",
    "                    closed_count = 0\n",
    "                #print(\"Open eyes found\")\n",
    "            \n",
    "            if closed_count >= 4 and not mixer.music.get_busy():\n",
    "                print(\"Pay attention!\") #chicchirichi\n",
    "                mixer.music.play()\n",
    "            \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        stop = time.time()\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.42406940460205\n"
     ]
    }
   ],
   "source": [
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4194400062487587"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_count/(stop-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
